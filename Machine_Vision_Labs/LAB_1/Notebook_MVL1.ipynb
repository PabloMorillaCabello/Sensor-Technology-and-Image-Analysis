{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f0880c",
   "metadata": {},
   "source": [
    "# **LAB 1: Fundamentals**\n",
    "\n",
    "## **General Goal**\n",
    "The goal of this project is to introduce the functionalities and a general workorder when using Image Processing \n",
    "and Toolboxes in Numpy and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e708398",
   "metadata": {},
   "source": [
    "Check up that all works ok ! :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "551e132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV: 4.12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    " \n",
    "print(\"OpenCV:\", cv.__version__)\n",
    "img = np.zeros((120, 400, 3), dtype=np.uint8)\n",
    "cv.putText(img, \"OpenCV OK\", (10, 80), cv.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 3)\n",
    "# If you installed a non-headless build, you can display a window:\n",
    "# cv.imshow(\"hello\", img); cv.waitKey(0)\n",
    "# Always safe (headless or not): save to file\n",
    "cv.imwrite(\"hello.png\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c3d465",
   "metadata": {},
   "source": [
    "## **Exercise 1 - Reading Image Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09705ed2",
   "metadata": {},
   "source": [
    "1. Open the image Original.png in Python using using the CV2.imread function, list all the image\n",
    "properties in a commented section in your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f1c9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Properties:\n",
      " - Shape (Height, Width, Channels): (540, 1050, 3)\n",
      " - Image Height: 540\n",
      " - Image Width: 1050\n",
      " - Number of Channels: 3\n",
      " - Data Type: uint8\n",
      " - Total Pixels: 1701000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\O'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\O'\n",
      "C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_8924\\3451966476.py:2: SyntaxWarning: invalid escape sequence '\\O'\n",
      "  image = cv.imread(\"Images_Lab_1\\Original.png\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nIMAGE PROPERTIES (Explained)\\n----------------------------\\nimage.shape\\n    - Returns a tuple: (height, width, channels)\\n      Example: (720, 1280, 3)\\n\\nimage.shape[0]\\n    - Height in pixels.\\n\\nimage.shape[1]\\n    - Width in pixels.\\n\\nimage.shape[2]\\n    - Number of color channels (e.g., 3 for BGR images).\\n\\nimage.dtype\\n    - Data type of the image array, typically uint8.\\n\\nimage.size\\n    - Total number of pixel values = height * width * channels\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the image\n",
    "image = cv.imread(\"Images_Lab_1\\Original.png\")\n",
    "\n",
    "# Check if the image loaded successfully\n",
    "if image is None:\n",
    "    print(\"Error: Could not load image. Make sure Original.png is in the working directory.\")\n",
    "else:\n",
    "    # Display image properties (printed)\n",
    "    print(\"Image Properties:\")\n",
    "    print(f\" - Shape (Height, Width, Channels): {image.shape}\")\n",
    "    print(f\" - Image Height: {image.shape[0]}\")\n",
    "    print(f\" - Image Width: {image.shape[1]}\")\n",
    "    print(f\" - Number of Channels: {image.shape[2] if len(image.shape) == 3 else 1}\")\n",
    "    print(f\" - Data Type: {image.dtype}\")\n",
    "    print(f\" - Total Pixels: {image.size}\")\n",
    "\n",
    "\"\"\"\n",
    "IMAGE PROPERTIES (Explained)\n",
    "----------------------------\n",
    "image.shape\n",
    "    - Returns a tuple: (height, width, channels)\n",
    "      Example: (720, 1280, 3)\n",
    "\n",
    "image.shape[0]\n",
    "    - Height in pixels.\n",
    "\n",
    "image.shape[1]\n",
    "    - Width in pixels.\n",
    "\n",
    "image.shape[2]\n",
    "    - Number of color channels (e.g., 3 for BGR images).\n",
    "\n",
    "image.dtype\n",
    "    - Data type of the image array, typically uint8.\n",
    "\n",
    "image.size\n",
    "    - Total number of pixel values = height * width * channels\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c7d090",
   "metadata": {},
   "source": [
    "2. There is a property in Original.png that has been automatically added by the CV2.imread function. Find\n",
    "the property using the CV2.imread function. What is the property and how does it affect the information\n",
    "in the image?\n",
    "\n",
    "A 3-channel BGR color representation (forced by cv2.IMREAD_COLOR).\n",
    "What actually happens internally?\n",
    "\n",
    "- If the PNG was grayscale (1 channel) ‚Üí OpenCV expands it to 3 channels using BGR.\n",
    "\n",
    "- If the PNG had RGBA (4 channels) ‚Üí OpenCV drops the alpha channel and returns 3-channel BGR.\n",
    "\n",
    "- If it had RGB ‚Üí OpenCV keeps 3 channels but converts to BGR ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5288e43a",
   "metadata": {},
   "source": [
    "## **Exercise 2 ‚Äì Finding Color values**\n",
    "In the previous exercise, you learned how to detect how many color channels an image has. Now it is time to \n",
    "extract specific RGB values in images. Find the RGB values in image colormap.jpg for the four positions indicated below, you will need to know what \n",
    "pixel to look for in the image. For this it can be useful to use paint as help: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2200603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Pixel in position (390,20), has a RGB value = [255 255 255]\n",
      "2. Pixel in position (230,130), has a RGB value = [ 52 204  51]\n",
      "3. Pixel in position (400,300), has a RGB value = [  0  71 227]\n",
      "4. Pixel in position (130,340), has a RGB value = [252 153  49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_8924\\606044286.py:1: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  im2 = cv.imread(\"Images_Lab_1\\colormap.jpg\")\n"
     ]
    }
   ],
   "source": [
    "im2 = cv.imread(\"Images_Lab_1\\colormap.jpg\")\n",
    "\n",
    "positions = [(390, 20), (230, 130), (400, 300), (130, 340)]\n",
    "\n",
    "\n",
    "for i, (x, y) in enumerate(positions):\n",
    "    print(f\"{i+1}. Pixel in position ({x},{y}), has a RGB value = {im2[x,y,:]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e91e2",
   "metadata": {},
   "source": [
    "What are the RGB values for the four points? Leave all your answers in the comments box inside the script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f97c0",
   "metadata": {},
   "source": [
    "1. Pixel in position (390,20), has a RGB value = [255 255 255]\n",
    "2. Pixel in position (230,130), has a RGB value = [ 52 204  51]\n",
    "3. Pixel in position (400,300), has a RGB value = [  0  71 227]\n",
    "4. Pixel in position (130,340), has a RGB value = [252 153  49]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0972de5c",
   "metadata": {},
   "source": [
    "## **Exercise 3 ‚Äì Binarization, Image stacking and trackbars**\n",
    "\n",
    "When working with images, displaying them side by side after making manipulations to them can be useful to \n",
    "follow what is going on when changing values in filters. Create a copy of the image ‚Äúpiece03.png‚Äù using the five methods below \n",
    "\n",
    "- cv.THRESH_BINARY\n",
    "- cv.THRESH_BINARY_INV\n",
    "- cv.THRESH_TRUNC\n",
    "- cv.THRESH_TOZERO\n",
    "- cv.THRESH_TOZERO_INV\n",
    "\n",
    "Now you should have five different binarized versions of ‚Äúpiece03.png‚Äù. You can view this as having five different and independent matrices containing image data for each method: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c97cb91",
   "metadata": {},
   "source": [
    "Now use a list to merge these images together and the NumPy stack function to display them vertically and \n",
    "horizontally. Think about how imshow reads the picture after this operation, what happens?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c519841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\pablo\\AppData\\Local\\Temp\\ipykernel_8924\\908840032.py:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  img = cv.imread(\"Images_Lab_1\\piece03.png\", cv.IMREAD_GRAYSCALE)\n"
     ]
    }
   ],
   "source": [
    "# ===========================[  LOAD IMAGE  ]=====================================\n",
    "img = cv.imread(\"Images_Lab_1\\piece03.png\", cv.IMREAD_GRAYSCALE)\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"piece03.png not found.\")\n",
    "\n",
    "max_value = 255\n",
    "\n",
    "\n",
    "# ===========================[  TRACKBAR CALLBACK  ]==============================\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "\n",
    "# ===========================[  WINDOW + TRACKBARS  ]=============================\n",
    "cv.namedWindow(\"Threshold Tuner\")\n",
    "\n",
    "cv.createTrackbar(\"THRESH\", \"Threshold Tuner\", 128, 255, nothing)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read trackbar position\n",
    "    t = cv.getTrackbarPos(\"THRESH\", \"Threshold Tuner\")\n",
    "\n",
    "    # Apply all five thresholding methods\n",
    "    _, th_binary     = cv.threshold(img, t, max_value, cv.THRESH_BINARY)\n",
    "    _, th_binary_inv = cv.threshold(img, t, max_value, cv.THRESH_BINARY_INV)\n",
    "    _, th_trunc      = cv.threshold(img, t, max_value, cv.THRESH_TRUNC)\n",
    "    _, th_tozero     = cv.threshold(img, t, max_value, cv.THRESH_TOZERO)\n",
    "    _, th_tozero_inv = cv.threshold(img, t, max_value, cv.THRESH_TOZERO_INV)\n",
    "\n",
    "    # Put in a visual grid (convert to BGR for display)\n",
    "    def lab(text, im):\n",
    "        im = cv.cvtColor(im, cv.COLOR_GRAY2BGR)\n",
    "        cv.putText(im, text, (10, 25), cv.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.7, (255, 255, 255), 2, cv.LINE_AA)\n",
    "        return im\n",
    "\n",
    "    images = [\n",
    "        lab(\"BINARY\", th_binary),\n",
    "        lab(\"BINARY_INV\", th_binary_inv),\n",
    "        lab(\"TRUNC\", th_trunc),\n",
    "        lab(\"TOZERO\", th_tozero),\n",
    "        lab(\"TOZERO_INV\", th_tozero_inv)\n",
    "    ]\n",
    "\n",
    "    # Pad images to make grid look nicer\n",
    "    def pad(im):\n",
    "        return cv.copyMakeBorder(im, 10, 10, 10, 10,\n",
    "                                 cv.BORDER_CONSTANT, value=(30, 30, 30))\n",
    "\n",
    "    images = [pad(im) for im in images]\n",
    "\n",
    "    # 2x3 grid (last one empty)\n",
    "    h, w = images[0].shape[:2]\n",
    "    empty = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    images.append(empty)\n",
    "\n",
    "    row1 = np.hstack(images[:3])\n",
    "    row2 = np.hstack(images[3:6])\n",
    "    grid = np.vstack((row1, row2))\n",
    "\n",
    "    display = cv.resize(grid, None, fx=0.1, fy=0.1)  # scale down to 10%\n",
    "    cv.imshow(\"Threshold Tuner\", display)\n",
    "\n",
    "\n",
    "    # Quit on ESC\n",
    "    if cv.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981e56c1",
   "metadata": {},
   "source": [
    "The three pieces (bright objects) appear most clearly when the threshold \n",
    "    value is roughly in the range **80‚Äì150**, depending on the image.\n",
    "    Below ~80 the threshold is too low and too much background is included.\n",
    "    Above ~150 the threshold removes parts of the pieces or loses smaller ones.\n",
    "    So a useful range where all threshold methods still show the three objects\n",
    "    is approximately **[80, 150]**.\n",
    "\n",
    "A2: Because an 8-bit grayscale image only contains intensity values from \n",
    "    **0 to 255**. Increasing the trackbar range (e.g., 0‚Äì1000) gives no real \n",
    "    improvement‚Äîthreshold values above 255 have **no effect** on the image.\n",
    "    Each pixel is stored as 1 byte, so any value outside 0‚Äì255 is meaningless.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a7c0a",
   "metadata": {},
   "source": [
    "## **Exercise 4 ‚Äì Extracting Color Channels**\n",
    "Read the image colormap.jpg and extract its color channels separately in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa6c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "grayscale = cv.imread(\"Images_Lab_1\\\\colormap.jpg\")\n",
    "\n",
    "# Extract channels\n",
    "B = grayscale[:, :, 0]\n",
    "G = grayscale[:, :, 1]\n",
    "R = grayscale[:, :, 2]\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Grayscale channel row\n",
    "# ---------------------------\n",
    "gray_images = (B, G, R)\n",
    "gray_row = np.hstack(gray_images)\n",
    "\n",
    "# Convert the grayscale row (2D) to BGR (3D) so it matches the colored row dimensions\n",
    "gray_row_bgr = cv.cvtColor(gray_row, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Colored channel row\n",
    "# ---------------------------\n",
    "# Create blank channels for merging\n",
    "zeros = np.zeros_like(B)\n",
    "\n",
    "blue_colored  = cv.merge((B, zeros, zeros))   # Blue channel emphasized\n",
    "green_colored = cv.merge((zeros, G, zeros))   # Green channel emphasized\n",
    "red_colored   = cv.merge((zeros, zeros, R))   # Red channel emphasized\n",
    "\n",
    "colored_images = (blue_colored, green_colored, red_colored)\n",
    "color_row = np.hstack(colored_images)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Stack rows vertically\n",
    "# ---------------------------\n",
    "final = np.vstack((gray_row_bgr, color_row))\n",
    "\n",
    "cv.imshow(\"Grayscale + Colored Channels\", final)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad13ad2d",
   "metadata": {},
   "source": [
    "## **Exercise 5 ‚Äì Preparing image for edge detection** \n",
    "\n",
    "To detect objects in an image, a common approach is to find the contours of the objects against the image background.  \n",
    "\n",
    "The contours are referred to as edges in image processing, and edges are registered when there is a sudden shift \n",
    "in pixel value between neighbouring pixels.   \n",
    "\n",
    "**The objective for exercise 5 is to find get only 4 objects outputted from cv2.findContours when analysing piece05.png.**\n",
    "\n",
    "In https://www.geeksforgeeks.org/find-and-draw-contours-using-opencv-python/ you can see an example of this operation as well as some sample code. However, the images used in that example are not representative to a real world image which usually contains colour information in RGB or grayscale format, so piece05.png needs further processing before the function cv2.findContours can be used. **In essence the result needs to be 4 when running the line print(\"Number of Contours found = \" + str(len(contours)))** \n",
    "\n",
    "To get there, several pre-processing steps needs to be performed to an image to get better perform edge detection, you can see examples of this in the link as well. \n",
    "\n",
    "Perform the following steps to the image piece05.png by prompting a LLM of your selection.  The preprocessing steps follow a standard structure that any LLM generates. \n",
    "\n",
    "- Explain the different steps and why they are necessary inside of your code by writing comments where the filters are used.   In a certain step, it uses canny edge detection and sometimes binarization.  \n",
    "\n",
    "- What filter is the best in what circumstance, is there something you can do when acquiring the image that will increase the accuracy of the image pre-processing? Write your answer in the bottom of your script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71166d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# LOAD IMAGE\n",
    "# =========================\n",
    "img = cv.imread(\"Images_Lab_1/piece05.png\")\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"piece05.png not found.\")\n",
    "\n",
    "# Convert to grayscale (contour detection works best on single-channel images)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# =========================\n",
    "# CREATE WINDOW + TRACKBARS\n",
    "# =========================\n",
    "cv.namedWindow(\"Contour Detection Tuner\")\n",
    "\n",
    "# Trackbars for Gaussian blur kernel size (must be odd)\n",
    "cv.createTrackbar(\"Blur\", \"Contour Detection Tuner\", 1, 20, lambda x: None)\n",
    "# Trackbars for Thresholding\n",
    "cv.createTrackbar(\"Thresh\", \"Contour Detection Tuner\", 128, 255, lambda x: None)\n",
    "cv.createTrackbar(\"MaxVal\", \"Contour Detection Tuner\", 255, 255, lambda x: None)\n",
    "# Trackbars for Canny edges\n",
    "cv.createTrackbar(\"Canny Low\", \"Contour Detection Tuner\", 50, 500, lambda x: None)\n",
    "cv.createTrackbar(\"Canny High\", \"Contour Detection Tuner\", 150, 500, lambda x: None)\n",
    "# Trackbars for Morphology (optional to close gaps)\n",
    "cv.createTrackbar(\"Morph Kernel\", \"Contour Detection Tuner\", 1, 20, lambda x: None)\n",
    "\n",
    "\n",
    "while True:\n",
    "    # =========================\n",
    "    # READ TRACKBAR VALUES\n",
    "    # =========================\n",
    "    ksize = cv.getTrackbarPos(\"Blur\", \"Contour Detection Tuner\")\n",
    "    if ksize % 2 == 0:  # Kernel size must be odd\n",
    "        ksize += 1\n",
    "\n",
    "    thresh_val = cv.getTrackbarPos(\"Thresh\", \"Contour Detection Tuner\")\n",
    "    max_val = cv.getTrackbarPos(\"MaxVal\", \"Contour Detection Tuner\")\n",
    "    canny_low = cv.getTrackbarPos(\"Canny Low\", \"Contour Detection Tuner\")\n",
    "    canny_high = cv.getTrackbarPos(\"Canny High\", \"Contour Detection Tuner\")\n",
    "\n",
    "    morph_k = cv.getTrackbarPos(\"Morph Kernel\", \"Contour Detection Tuner\")\n",
    "    if morph_k % 2 == 0:\n",
    "        morph_k += 1\n",
    "\n",
    "    # =========================\n",
    "    # STEP 1: SMOOTHING\n",
    "    # =========================\n",
    "    # Gaussian blur reduces small noise and intensity variations\n",
    "    blurred = cv.GaussianBlur(gray, (ksize, ksize), 0)\n",
    "\n",
    "    # =========================\n",
    "    # STEP 2: THRESHOLDING\n",
    "    # =========================\n",
    "    # Converts image to binary to separate objects from background\n",
    "    _, binary = cv.threshold(blurred, thresh_val, max_val, cv.THRESH_BINARY)\n",
    "\n",
    "    # =========================\n",
    "    # STEP 3: CANNY\n",
    "    # =========================\n",
    "    # Detect edges by finding sudden intensity changes\n",
    "    edges = cv.Canny(blurred, canny_low, canny_high)\n",
    "\n",
    "    # =========================\n",
    "    # STEP 4: MORPH CLOSE\n",
    "    # =========================\n",
    "    # Closing gaps in edges to get full contours\n",
    "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (morph_k, morph_k))\n",
    "    edges_closed = cv.morphologyEx(edges, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # =========================\n",
    "    # STEP 5: FIND CONTOURS\n",
    "    # =========================\n",
    "    contours, _ = cv.findContours(edges_closed, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    cont_img = img.copy()\n",
    "    cv.drawContours(cont_img, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Add contour count text\n",
    "    cv.putText(\n",
    "        cont_img,\n",
    "        f\"Contours: {len(contours)}\",\n",
    "        (150, 150),\n",
    "        cv.FONT_HERSHEY_SIMPLEX,\n",
    "        5.0,\n",
    "        (0, 0, 255),\n",
    "        10\n",
    "    )\n",
    "\n",
    "    # =========================\n",
    "    # DISPLAY ALL STEPS IN A ROW\n",
    "    # =========================\n",
    "    disp_h = 250\n",
    "\n",
    "    def r(img):\n",
    "        return cv.resize(img, (int(img.shape[1] * disp_h / img.shape[0]), disp_h))\n",
    "\n",
    "    gray_bgr    = cv.cvtColor(r(gray), cv.COLOR_GRAY2BGR)\n",
    "    blurred_bgr = cv.cvtColor(r(blurred), cv.COLOR_GRAY2BGR)\n",
    "    binary_bgr  = cv.cvtColor(r(binary), cv.COLOR_GRAY2BGR)\n",
    "    edges_bgr   = cv.cvtColor(r(edges_closed), cv.COLOR_GRAY2BGR)\n",
    "    cont_small  = r(cont_img)\n",
    "\n",
    "    row = np.hstack([\n",
    "        gray_bgr,\n",
    "        blurred_bgr,\n",
    "        binary_bgr,\n",
    "        edges_bgr,\n",
    "        cont_small\n",
    "    ])\n",
    "\n",
    "    cv.imshow(\"Pipeline Overview\", row)\n",
    "\n",
    "    # Main window image\n",
    "    scale = 0.3\n",
    "    display = cv.resize(cont_img, None, fx=scale, fy=scale)\n",
    "    cv.imshow(\"Contour Detection Tuner\", display)\n",
    "\n",
    "    # Quit on ESC\n",
    "    if cv.waitKey(10) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a862c7",
   "metadata": {},
   "source": [
    "üìù Comments on Filters and Image Acquisition\n",
    "1) Gaussian Blur\n",
    "\n",
    "Reduces noise to avoid false edges.\n",
    "\n",
    "Works well for images with grainy or textured backgrounds.\n",
    "\n",
    "2) Thresholding / Binarization\n",
    "\n",
    "Separates foreground objects from background.\n",
    "\n",
    "Effective when objects have clear intensity differences from the background.\n",
    "\n",
    "Adaptive thresholding helps when lighting is uneven.\n",
    "\n",
    "3) Canny Edge Detection\n",
    "\n",
    "Detects edges using intensity gradients.\n",
    "\n",
    "Sensitive to noise ‚Üí smoothing first is important.\n",
    "\n",
    "Best when accurate shape boundaries are required.\n",
    "\n",
    "4) Morphological Operations\n",
    "\n",
    "Closing (dilation ‚Üí erosion) connects broken edges.\n",
    "\n",
    "Useful when contours have small gaps or noise.\n",
    "\n",
    "5) Best Filter for Each Situation\n",
    "\n",
    "High contrast objects: simple THRESH_BINARY.\n",
    "\n",
    "Detailed objects: Gaussian blur ‚Üí Canny edges.\n",
    "\n",
    "Noisy or uneven lighting: Gaussian blur ‚Üí Adaptive threshold ‚Üí Morphological closing.\n",
    "\n",
    "6) Image Acquisition Tips\n",
    "\n",
    "Maintain uniform lighting and high contrast between object and background.\n",
    "\n",
    "Use fast shutter speeds to reduce motion blur.\n",
    "\n",
    "Reduce camera noise (low ISO, clean lens/sensor).\n",
    "\n",
    "Ensure objects are fully in frame and well separated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54322b76",
   "metadata": {},
   "source": [
    "## **Exercise 6 ‚Äì Finding Position**\n",
    "\n",
    " Using OpenCV, find the centre position in pixels of the object inside the colour image star.png by \n",
    "\n",
    "- Using a canny filter    \n",
    "- Using Binarization filter\n",
    "\n",
    "Leave all your answers in the comments box inside the script clearly diversifying which coordinates you get \n",
    "when using the different filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37d78c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canny centroid = (88, 113)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv.imread(\"Images_Lab_1/star.png\")\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Canny edge detection\n",
    "edges = cv.Canny(gray, 50, 150)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv.findContours(edges, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Take the largest contour (the star)\n",
    "cnt = max(contours, key=cv.contourArea)\n",
    "\n",
    "# Compute centroid using image moments\n",
    "M = cv.moments(cnt)\n",
    "cx = int(M['m10'] / M['m00'])\n",
    "cy = int(M['m01'] / M['m00'])\n",
    "\n",
    "print(\"Canny centroid =\", (cx, cy))\n",
    "\n",
    "# Draw centroid\n",
    "cv.circle(img, (cx, cy), 6, (0, 255, 0), -1)\n",
    "cv.imshow(\"Canny Center\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94e5aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary centroid = (88, 113)\n"
     ]
    }
   ],
   "source": [
    "# Load image (try the Images_Lab_1 path used elsewhere, then fallback to current dir)\n",
    "img = cv.imread(\"Images_Lab_1/star.png\")\n",
    "if img is None:\n",
    "\timg = cv.imread(\"star.png\")\n",
    "if img is None:\n",
    "\traise FileNotFoundError(\"star.png not found. Place it in 'Images_Lab_1/' or the notebook working directory.\")\n",
    "\n",
    "# Convert to grayscale (safe because img is confirmed loaded)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Inverted threshold so the star is white and background is black\n",
    "_, binary = cv.threshold(gray, 128, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "if len(contours) == 0:\n",
    "\traise RuntimeError(\"No contours found in the binary image. Check thresholding or image path.\")\n",
    "\n",
    "# Largest contour = star\n",
    "cnt = max(contours, key=cv.contourArea)\n",
    "\n",
    "# Compute centroid (protect against zero area)\n",
    "M = cv.moments(cnt)\n",
    "if M['m00'] == 0:\n",
    "\traise RuntimeError(\"Contour has zero area, cannot compute centroid.\")\n",
    "cx = int(M['m10'] / M['m00'])\n",
    "cy = int(M['m01'] / M['m00'])\n",
    "\n",
    "print(\"Binary centroid =\", (cx, cy))\n",
    "\n",
    "# Draw centroid on a copy to avoid modifying original unexpectedly\n",
    "out = img.copy()\n",
    "cv.circle(out, (cx, cy), 6, (0, 255, 0), -1)\n",
    "cv.imshow(\"Binary Center\", out)\n",
    "cv.imshow(\"Binary Mask\", binary)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa02df6",
   "metadata": {},
   "source": [
    "## **Exercise 7 ‚Äì Finding Orientation**  \n",
    "Using OpenCV, Find the orientation in degrees of the object inside the color image tree.png by \n",
    "\n",
    "- Using a canny filter  \n",
    "- Using binarization filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2053a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orientation using Canny = 125.2736486368268 degrees\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Load image with fallbacks to common paths to avoid None image\n",
    "img = cv.imread(\"Images_Lab_1/tree.png\")\n",
    "if img is None:\n",
    "\timg = cv.imread(\"Images_Lab_1/tree.png\")\n",
    "if img is None:\n",
    "\timg = cv.imread(\"Images_Lab_1\\\\tree.png\")\n",
    "if img is None:\n",
    "\traise FileNotFoundError(\"tree.png not found. Place it in the notebook working directory or 'Images_Lab_1/'.\")\n",
    "\n",
    "# Convert to grayscale (safe now since img is loaded)\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# --- Canny edges ---\n",
    "edges = cv.Canny(gray, 50, 150)\n",
    "\n",
    "# Find contours\n",
    "contours_info = cv.findContours(edges, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "# Compatibility for OpenCV versions (findContours returns 2 or 3 values)\n",
    "if len(contours_info) == 3:\n",
    "\t_, contours, _ = contours_info\n",
    "else:\n",
    "\tcontours, _ = contours_info\n",
    "\n",
    "# Ensure we have at least one contour\n",
    "if len(contours) == 0:\n",
    "\traise RuntimeError(\"No contours found. Try adjusting Canny thresholds or check the input image.\")\n",
    "\n",
    "# Use the largest contour (tree)\n",
    "cnt = max(contours, key=cv.contourArea)\n",
    "\n",
    "# Convert contour to Nx2 array of points\n",
    "data_pts = cnt.reshape(-1, 2).astype(np.float32)\n",
    "\n",
    "# PCA\n",
    "# cv.PCACompute2 requires a 'mean' argument (can be None to compute internally)\n",
    "mean, eigenvectors, eigenvalues = cv.PCACompute2(data_pts, mean=None)\n",
    "\n",
    "# Orientation angle (principal eigenvector)\n",
    "vx, vy = eigenvectors[0]\n",
    "angle = math.degrees(math.atan2(vy, vx))\n",
    "\n",
    "print(\"Orientation using Canny =\", angle, \"degrees\")\n",
    "\n",
    "# Optional: draw axis\n",
    "# mean may be shape (1,2), flatten it to get coordinates\n",
    "center_coords = tuple(int(x) for x in mean.ravel())\n",
    "p2 = (int(center_coords[0] + vx * 100), int(center_coords[1] + vy * 100))\n",
    "cv.circle(img, center_coords, 5, (0, 0, 255), -1)\n",
    "cv.line(img, center_coords, p2, (0, 255, 0), 3)\n",
    "\n",
    "cv.imshow(\"Orientation (Canny)\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3482a3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orientation using Binarization = 125.68969276065359 degrees\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Load image (try common paths)\n",
    "img = cv.imread(\"Images_Lab_1/tree.png\")\n",
    "if img is None:\n",
    "\timg = cv.imread(\"Images_Lab_1\\\\tree.png\")\n",
    "if img is None:\n",
    "\timg = cv.imread(\"tree.png\")\n",
    "if img is None:\n",
    "\traise FileNotFoundError(\"tree.png not found. Place it in 'Images_Lab_1/' or the notebook working directory.\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold (invert if tree is dark)\n",
    "_, binary = cv.threshold(gray, 128, 255, cv.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours (compatibility for different OpenCV returns)\n",
    "contours_info = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "if len(contours_info) == 3:\n",
    "\t_, contours, _ = contours_info\n",
    "else:\n",
    "\tcontours, _ = contours_info\n",
    "\n",
    "if len(contours) == 0:\n",
    "\traise RuntimeError(\"No contours found. Check thresholding or image path.\")\n",
    "\n",
    "# Largest contour = tree\n",
    "cnt = max(contours, key=cv.contourArea)\n",
    "\n",
    "# Prepare points for PCA\n",
    "data_pts = cnt.reshape(-1, 2).astype(np.float32)\n",
    "\n",
    "# PCA\n",
    "# Some OpenCV builds require an explicit 'mean' argument for PCACompute2.\n",
    "# Provide None to let OpenCV compute the mean internally.\n",
    "# This call returns mean, eigenvectors, eigenvalues (or similar depending on version).\n",
    "mean, eigenvectors, eigenvalues = cv.PCACompute2(data_pts, None)\n",
    "\n",
    "# Orientation (principal eigenvector)\n",
    "vx, vy = eigenvectors[0]\n",
    "angle = math.degrees(math.atan2(vy, vx))\n",
    "\n",
    "print(\"Orientation using Binarization =\", angle, \"degrees\")\n",
    "\n",
    "# Optional: draw axis\n",
    "# Ensure mean is flattened to (x,y) ints\n",
    "center = tuple(int(x) for x in mean.ravel())\n",
    "p2 = (int(center[0] + vx * 100), int(center[1] + vy * 100))\n",
    "cv.circle(img, center, 5, (0, 0, 255), -1)\n",
    "cv.line(img, center, p2, (0, 255, 0), 3)\n",
    "\n",
    "cv.imshow(\"Orientation (Binary)\", img)\n",
    "cv.imshow(\"Binary Mask\", binary)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e82f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
